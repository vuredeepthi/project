{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2385,
     "status": "ok",
     "timestamp": 1747633332982,
     "user": {
      "displayName": "Uma Shankara",
      "userId": "16546725700394705844"
     },
     "user_tz": -330
    },
    "id": "q1INQsGpBFZR",
    "outputId": "8514fc8e-d210-4e08-f685-d9dce4732c78"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 22758,
     "status": "ok",
     "timestamp": 1747633359374,
     "user": {
      "displayName": "Uma Shankara",
      "userId": "16546725700394705844"
     },
     "user_tz": -330
    },
    "id": "j1nosRhpBGsT",
    "outputId": "6c0c57e8-f6a0-460d-a3e1-38fd5661b9b6"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, classification_report, confusion_matrix \u001b[38;5;66;03m# Add confusion_matrix\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlibrosa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix # Add confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from google.colab import drive\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Configuration ---\n",
    "# Define directories for your two classes: REAL and FAKE (Mimicry)\n",
    "AUDIO_DIRS = {\n",
    "    \"REAL\": \"/content/drive/My Drive/a2/KAGGLE/AUDIO/REAL\",\n",
    "    \"FAKE\": \"/content/drive/My Drive/a2/KAGGLE/AUDIO/FAKE\", # Your Mimicry data\n",
    "}\n",
    "\n",
    "# Define directories for where to save the base MFCC features for these two classes\n",
    "FEATURE_DIRS = {\n",
    "    \"REAL\": \"/content/drive/My Drive/a2/KAGGLE/FEATURES/REAL_MFCC_Enhanced\",\n",
    "    \"FAKE\": \"/content/drive/My Drive/a2/KAGGLE/FEATURES/FAKE_MFCC_Enhanced\",\n",
    "}\n",
    "\n",
    "# Map class names to numerical labels for binary classification\n",
    "# Ensure these match your desired output mapping\n",
    "CLASS_LABELS = {\n",
    "    \"REAL\": 1,  # Assign 1 to Real (often treated as the positive class)\n",
    "    \"FAKE\": 0,  # Assign 0 to Fake/Mimicry (often treated as the negative class)\n",
    "}\n",
    "# Create a reverse mapping for interpreting predictions\n",
    "LABEL_TO_CLASS = {v: k for k, v in CLASS_LABELS.items()}\n",
    "\n",
    "\n",
    "# MFCC parameters (should be consistent throughout)\n",
    "n_mfcc = 40\n",
    "hop_length = 512\n",
    "n_fft = 2048\n",
    "\n",
    "\n",
    "# --- 1. Extract Base MFCC Features for both classes ---\n",
    "\n",
    "def extract_and_save_mfcc_features(audio_dir, output_features_dir, n_mfcc, hop_length, n_fft):\n",
    "    \"\"\"\n",
    "    Extracts MFCC features from audio files in a directory and saves them as .npy files.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_features_dir, exist_ok=True)\n",
    "    all_audio_filenames = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
    "\n",
    "    print(f\"Starting base MFCC extraction for {len(all_audio_filenames)} files in {audio_dir}...\")\n",
    "\n",
    "    for filename in all_audio_filenames:\n",
    "        audio_file_path = os.path.join(audio_dir, filename)\n",
    "        feature_output_path = os.path.join(output_features_dir, f\"{os.path.splitext(filename)[0]}.npy\")\n",
    "\n",
    "        if os.path.exists(feature_output_path):\n",
    "            print(f\"Base MFCC features for {filename} already exist. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            y, sr = librosa.load(audio_file_path, sr=None)\n",
    "            mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "            np.save(feature_output_path, mfccs)\n",
    "            print(f\"Base MFCCs saved to {feature_output_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error extracting base MFCCs from {audio_file_path}: {e}\")\n",
    "\n",
    "# Call the function for each audio directory defined in AUDIO_DIRS\n",
    "for class_name, audio_dir_path in AUDIO_DIRS.items():\n",
    "    output_features_dir_path = FEATURE_DIRS[class_name]\n",
    "    extract_and_save_mfcc_features(audio_dir_path, output_features_dir_path, n_mfcc, hop_length, n_fft)\n",
    "\n",
    "print(\"\\nCompleted base MFCC extraction for all specified audio directories.\")\n",
    "\n",
    "\n",
    "# --- 2. Visualize Extracted Features (Example for one file from each class) ---\n",
    "print(\"\\n--- Visualizing Example Features ---\")\n",
    "for class_name, feature_dir_path in FEATURE_DIRS.items():\n",
    "    files_in_dir = [f for f in os.listdir(feature_dir_path) if f.endswith(\".npy\")]\n",
    "    if files_in_dir:\n",
    "        example_feature_file = os.path.join(feature_dir_path, files_in_dir[0])\n",
    "        try:\n",
    "            features_to_visualize = np.load(example_feature_file)\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            # For MFCCs, specshow expects (n_features, n_time)\n",
    "            # Assuming a common sampling rate like 16000 Hz for display purposes\n",
    "            librosa.display.specshow(features_to_visualize, x_axis='time', sr=16000)\n",
    "            plt.colorbar(format=\"%+2.f dB\")\n",
    "            plt.title(f'MFCCs for {class_name} (Example: {files_in_dir[0]})')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "             print(f\"Could not visualize features for {example_feature_file}: {e}\")\n",
    "    else:\n",
    "        print(f\"No feature files found for {class_name} visualization.\")\n",
    "\n",
    "\n",
    "# --- 3. Load Enhanced Features and Create Labels for both classes ---\n",
    "\n",
    "def load_features_and_create_labels_enhanced(features_dir, label):\n",
    "    \"\"\"\n",
    "    Loads base MFCC features from .npy files, computes Delta and Delta-Delta,\n",
    "    and aggregates features by taking mean and variance across time.\n",
    "\n",
    "    Args:\n",
    "        features_dir (str): Directory containing the base MFCC .npy files.\n",
    "        label (int): The numerical label (0 or 1) to assign to these features.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - features_list (list): List of aggregated feature vectors.\n",
    "            - labels_list (list): List of corresponding labels.\n",
    "            - filenames_list (list): List of original filenames.\n",
    "    \"\"\"\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    filenames_list = []\n",
    "\n",
    "    print(f\"Loading enhanced features from {features_dir} (Label: {label})...\")\n",
    "\n",
    "    for filename in os.listdir(features_dir):\n",
    "        if filename.endswith(\".npy\"):\n",
    "            feature_path = os.path.join(features_dir, filename)\n",
    "            try:\n",
    "                mfccs = np.load(feature_path)\n",
    "\n",
    "                if mfccs.ndim != 2:\n",
    "                     print(f\"Warning: Skipping {filename} due to unexpected base MFCC shape: {mfccs.shape}\")\n",
    "                     continue\n",
    "\n",
    "                # Check if there are enough time steps for delta computation\n",
    "                if mfccs.shape[1] < 3: # Need at least 3 time steps for 2nd order delta\n",
    "                     print(f\"Warning: Not enough time steps ({mfccs.shape[1]}) for delta computation for {filename}. Skipping.\")\n",
    "                     continue\n",
    "\n",
    "                mfccs_delta = librosa.feature.delta(mfccs)\n",
    "                mfccs_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "                # Delta/Delta-Delta can sometimes have slightly different time dimensions\n",
    "                # due to boundary effects depending on the implementation details/versions.\n",
    "                # A robust approach might pad or truncate, but a simple check is below.\n",
    "                if mfccs_delta.shape[-1] != mfccs.shape[-1] or mfccs_delta2.shape[-1] != mfccs.shape[-1]:\n",
    "                     print(f\"Warning: Delta/Delta-Delta time dimensions mismatch for {filename}. Skipping.\")\n",
    "                     continue\n",
    "\n",
    "\n",
    "                # Combine base MFCCs, Delta, and Delta-Delta along the feature axis (axis=0)\n",
    "                # The shape of combined_mfccs will be (n_mfcc * 3, time_steps)\n",
    "                combined_mfccs = np.concatenate((mfccs, mfccs_delta, mfccs_delta2), axis=0)\n",
    "\n",
    "                # Aggregate features (mean and variance) across time (axis=1 of the combined features)\n",
    "                # The shape of combined_mfccs is (total_features, time_steps)\n",
    "                combined_mfccs_mean = np.mean(combined_mfccs, axis=1)\n",
    "                combined_mfccs_var = np.var(combined_mfccs, axis=1)\n",
    "\n",
    "                # Concatenate mean and variance to create a single feature vector per audio clip\n",
    "                # The shape of aggregated_features will be (total_features * 2,)\n",
    "                aggregated_features = np.concatenate((combined_mfccs_mean, combined_mfccs_var))\n",
    "\n",
    "                features_list.append(aggregated_features)\n",
    "                labels_list.append(label)\n",
    "                # Reconstruct the original filename (assuming .wav) from the .npy filename\n",
    "                original_filename = os.path.splitext(filename)[0] + \".wav\"\n",
    "                filenames_list.append(original_filename)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading or processing features from {feature_path}: {e}\")\n",
    "                # Optionally, append None or a placeholder to maintain list length if needed later\n",
    "\n",
    "    return features_list, labels_list, filenames_list\n",
    "\n",
    "# --- Load All Features and Labels ---\n",
    "\n",
    "# Load features and labels for both classes\n",
    "all_features = []\n",
    "all_labels = []\n",
    "all_filenames = []\n",
    "\n",
    "for class_name, feature_dir_path in FEATURE_DIRS.items():\n",
    "    # Use the label from the CLASS_LABELS dictionary\n",
    "    label = CLASS_LABELS[class_name]\n",
    "    class_features, class_labels, class_filenames = load_features_and_create_labels_enhanced(feature_dir_path, label)\n",
    "    all_features.extend(class_features)\n",
    "    all_labels.extend(class_labels)\n",
    "    all_filenames.extend(class_filenames)\n",
    "\n",
    "\n",
    "print(f\"\\nLoaded {len(all_features)} feature vectors from all classes.\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(all_features)\n",
    "y = np.array(all_labels)\n",
    "\n",
    "print(f\"Shape of feature array (X): {X.shape}\")\n",
    "print(f\"Shape of label array (y): {y.shape}\")\n",
    "# Show the distribution of the two binary labels\n",
    "print(f\"Distribution of labels in y (0: FAKE, 1: REAL): {np.bincount(y)}\")\n",
    "\n",
    "\n",
    "# Check for empty arrays\n",
    "if X.size == 0:\n",
    "    print(\"Error: No features were successfully loaded. Cannot proceed with training.\")\n",
    "else:\n",
    "    # --- 4. Preprocess Features (Scaling) ---\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    print(\"Features scaled.\")\n",
    "\n",
    "    # --- 5. Split Data ---\n",
    "    # Using stratify=y to maintain class distribution in train and test sets\n",
    "    # Ensure there are at least two samples and two unique classes\n",
    "    if len(X_scaled) < 2 or len(np.unique(y)) < 2:\n",
    "         print(\"Error: Not enough samples or classes (need at least 2) to perform train/test split.\")\n",
    "         # Handle this case, e.g., exit or skip training\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "        print(f\"\\nData split: {len(X_train)} training samples, {len(X_test)} testing samples.\")\n",
    "        print(\"Training set class distribution (0: FAKE, 1: REAL):\", np.bincount(y_train))\n",
    "        print(\"Testing set class distribution (0: FAKE, 1: REAL):\", np.bincount(y_test))\n",
    "\n",
    "\n",
    "        # --- 6. Train a Classifier (RandomForest - suitable for binary) ---\n",
    "        model = RandomForestClassifier(n_estimators=200, random_state=42, class_weight='balanced', n_jobs=-1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        print(\"\\nRandom Forest model trained (Binary Classification).\")\n",
    "\n",
    "        # --- 7. Evaluate the Model ---\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        print(f\"\\nModel Accuracy on Test Set: {accuracy:.4f}\")\n",
    "\n",
    "        # Print classification report (binary)\n",
    "        print(\"\\nClassification Report:\")\n",
    "        # Provide target_names for better readability (matching the labels 0 and 1)\n",
    "        target_names = [LABEL_TO_CLASS[i] for i in sorted(LABEL_TO_CLASS.keys())]\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "\n",
    "        # Visualize Confusion Matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(cm)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # --- 8. Code to predict on a single new audio file (after training) ---\n",
    "\n",
    "        def predict_single_audio_binary(audio_file_path, model, scaler, n_mfcc, hop_length, n_fft, label_to_class_map):\n",
    "            \"\"\"\n",
    "            Loads a single audio file, extracts and preprocesses enhanced features,\n",
    "            makes a prediction, and interprets the prediction using the class map.\n",
    "            This version is tailored for binary (FAKE/REAL) output.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                y, sr = librosa.load(audio_file_path, sr=None)\n",
    "                mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, hop_length=hop_length, n_fft=n_fft)\n",
    "\n",
    "                if mfccs.ndim != 2:\n",
    "                     print(f\"Error: Unexpected MFCC shape for {audio_file_path} during delta computation: {mfccs.shape}\")\n",
    "                     return \"Error: Feature extraction failed\"\n",
    "\n",
    "                if mfccs.shape[1] < 3: # Need at least 3 time steps for 2nd order delta\n",
    "                     print(f\"Error: Not enough time steps ({mfccs.shape[1]}) for delta computation for {audio_file_path}. Skipping prediction.\")\n",
    "                     return \"Error: Not enough data for features\"\n",
    "\n",
    "                mfccs_delta = librosa.feature.delta(mfccs)\n",
    "                mfccs_delta2 = librosa.feature.delta(mfccs, order=2)\n",
    "\n",
    "                if mfccs_delta.shape[-1] != mfccs.shape[-1] or mfccs_delta2.shape[-1] != mfccs.shape[-1]:\n",
    "                     print(f\"Error: Delta/Delta-Delta time dimensions mismatch for {audio_file_path}. Skipping prediction.\")\n",
    "                     return \"Error: Feature dimension mismatch\"\n",
    "\n",
    "                combined_mfccs = np.concatenate((mfccs, mfccs_delta, mfccs_delta2), axis=0)\n",
    "\n",
    "                combined_mfccs_mean = np.mean(combined_mfccs, axis=1)\n",
    "                combined_mfccs_var = np.var(combined_mfccs, axis=1)\n",
    "                aggregated_features = np.concatenate((combined_mfccs_mean, combined_mfccs_var))\n",
    "\n",
    "                aggregated_features = aggregated_features.reshape(1, -1)\n",
    "\n",
    "                scaled_features = scaler.transform(aggregated_features)\n",
    "\n",
    "                # Make the prediction (returns an array with one element)\n",
    "                prediction_label = model.predict(scaled_features)[0]\n",
    "\n",
    "                # Interpret the prediction using the map\n",
    "                prediction_class = label_to_class_map.get(prediction_label, \"Unknown Class\")\n",
    "\n",
    "                return prediction_class\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing and predicting for {audio_file_path}: {e}\")\n",
    "                return f\"Error: {str(e)}\"\n",
    "\n",
    "\n",
    "        # --- Example Usage for a single prediction ---\n",
    "\n",
    "        # Specify the path to a new audio file you want to classify\n",
    "        # MAKE SURE this file exists and is one of the test files (or a completely new file)\n",
    "        test_audio_file_path_example = \"/content/drive/My Drive/a2/KAGGLE/AUDIO/FAKE/musk-to-linus.wav\" # REPLACE with a valid path to a file you want to test\n",
    "\n",
    "        # Make the prediction\n",
    "        if 'model' in locals() and 'scaler' in locals() and 'LABEL_TO_CLASS' in locals():\n",
    "            prediction_result = predict_single_audio_binary( # Use the binary version\n",
    "                test_audio_file_path_example,\n",
    "                model,\n",
    "                scaler,\n",
    "                n_mfcc,\n",
    "                hop_length,\n",
    "                n_fft,\n",
    "                LABEL_TO_CLASS # Pass the mapping\n",
    "            )\n",
    "            print(f\"\\nThe audio file '{test_audio_file_path_example}' is predicted as: {prediction_result}\")\n",
    "        else:\n",
    "            print(\"\\nModel, scaler, or label mapping not available. Please run the training code first.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPnW4yrrEdtLnkyGzsITr61",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
